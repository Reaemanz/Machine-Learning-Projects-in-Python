{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ab037723-587e-a537-97c7-fcdf577f40af"
   },
   "source": [
    "Hello there everyone!\n",
    "\n",
    "I am new to this competition but it looks like this dataset leads to overfitting problems. In addition, it seems like Mercedes is interested in reducing the dataset to a few meaningful variables. Therefore, I thought it was a good idea to try one of the best linear models I know for tackling overfitting that works also as a feature selection method: **Elastic Nets**.\n",
    "\n",
    "Elastic Nets are essentially a **Lasso/Ridge** hybrid, that entails the minimization of an objective function that includes both **L1** (Lasso) and **L2** (Ridge) norms. You can find more about ElasticNets [here][1].  \n",
    "\n",
    "For the sake of this notebook it is important to notice that Elastic nets depends on two parameters: \n",
    "\n",
    "* the **l1_ratio**, i.e. the tradeoff between the two norms (l1_ratio = 0 --> Ridge,  l1_ratio = 1 --> Lasso, 0<l1_ration<1 --> Mix of the two);\n",
    "* **alpha**, that regulates the amount of penalty applied.\n",
    "\n",
    "It is important to know that minimizing the L1 norm will force some coefficients to shrink to zero, and that's why Elastic Nets can be used as feature selection techniques. Besides, when there's a high degree of collinearity in the data, the cross-validation procedure used to determine these two parameters will return low l1_ratio since Ridge tends to outperform Lasso in these cases.\n",
    "\n",
    "Ok... let's use scikit-learn and see how these methods perfom and which features they select!\n",
    "\n",
    "  [1]: http://www.onthelambda.com/2015/08/19/kickin-it-with-elastic-net-regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "daa3a95f-f785-c953-0dd0-25b5108166de"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "5c25d1c7-7d5d-23a5-f48e-1ca72e6065c4"
   },
   "outputs": [],
   "source": [
    "# load modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "15316c87-5ea9-3c9b-4d55-5a254a9d06ef"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df  = pd.read_csv('../input/train.csv')\n",
    "test_df  = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "e39bfe7d-2054-024d-c349-288104bde187"
   },
   "outputs": [],
   "source": [
    "# get train_y, test ids and unite datasets to perform\n",
    "train_y = train_df['y']\n",
    "train_df.drop('y', axis = 1, inplace = True)\n",
    "test_ids = test_df.ID.values\n",
    "all_df = pd.concat([train_df,test_df], axis = 0)\n",
    "\n",
    "# ...one hot encoding of categorical variables\n",
    "categorical =  [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]\n",
    "for f in categorical:\n",
    "    dummies = pd.get_dummies(all_df[f], prefix = f, prefix_sep = '_')\n",
    "    all_df = pd.concat([all_df, dummies], axis = 1)\n",
    "\n",
    "# drop original categorical features\n",
    "all_df.drop(categorical, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "f88fb001-8efc-bd59-f34b-ba4b5a06b7f9"
   },
   "outputs": [],
   "source": [
    "# get feature dataset for test and training        \n",
    "train_X = all_df.drop([\"ID\"], axis=1).iloc[:len(train_df),:]\n",
    "test_X = all_df.drop([\"ID\"], axis=1).iloc[len(train_df):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "3c322d7e-774b-93e4-b600-d7d76d44332a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X10  X11  X12  X13  X14  X15  X16  X17  X18  X19  ...   X8_p  X8_q  X8_r  \\\n",
      "0    0    0    0    1    0    0    0    0    1    0  ...      0     0     0   \n",
      "1    0    0    0    0    0    0    0    0    1    0  ...      0     0     0   \n",
      "2    0    0    0    0    0    0    0    1    0    0  ...      0     0     0   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
      "4    0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
      "\n",
      "   X8_s  X8_t  X8_u  X8_v  X8_w  X8_x  X8_y  \n",
      "0     0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     1     0  \n",
      "3     0     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 579 columns]\n",
      "   X10  X11  X12  X13  X14  X15  X16  X17  X18  X19  ...   X8_p  X8_q  X8_r  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
      "1    0    0    0    0    0    0    0    0    0    1  ...      0     0     0   \n",
      "2    0    0    0    0    1    0    0    0    0    0  ...      0     0     0   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
      "4    0    0    0    0    1    0    0    0    0    0  ...      0     0     0   \n",
      "\n",
      "   X8_s  X8_t  X8_u  X8_v  X8_w  X8_x  X8_y  \n",
      "0     0     0     0     0     1     0     0  \n",
      "1     0     0     0     0     0     0     1  \n",
      "2     0     0     0     0     0     0     0  \n",
      "3     0     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 579 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_X.head())\n",
    "print(test_X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fccc4896-c86a-25ce-1133-1ff4a363f665"
   },
   "source": [
    "# Model development and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "f132b2ad-edd0-4456-5fd8-739463066d77"
   },
   "outputs": [],
   "source": [
    "# Let's perform a cross-validation to find the best combination of alpha and l1_ratio\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "\n",
    "cv_model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, .995, 1], eps=0.001, n_alphas=100, fit_intercept=True, \n",
    "                        normalize=True, precompute='auto', max_iter=2000, tol=0.0001, cv=5, \n",
    "                        copy_X=True, verbose=0, n_jobs=-1, positive=False, random_state=None, selection='cyclic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b19e6690-9303-d270-66e5-4b2ae164592c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=None, copy_X=True, cv=5, eps=0.001, fit_intercept=True,\n",
       "       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 0.995, 1], max_iter=2000,\n",
       "       n_alphas=100, n_jobs=-1, normalize=True, positive=False,\n",
       "       precompute='auto', random_state=None, selection='cyclic',\n",
       "       tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "d7ba4139-bdec-6d31-87fc-d6a0ab051893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.00314540\n",
      "Optimal l1_ratio: 1.000\n",
      "Number of iterations 603\n"
     ]
    }
   ],
   "source": [
    "print('Optimal alpha: %.8f'%cv_model.alpha_)\n",
    "print('Optimal l1_ratio: %.3f'%cv_model.l1_ratio_)\n",
    "print('Number of iterations %d'%cv_model.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7459711f-92f4-b381-a006-53c9ff327471"
   },
   "source": [
    "**l1_ratio = 1**, that means we are just using Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c84f21b4-7b47-1df5-e3d5-e579b97101d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.0031453993038814206, copy_X=True, fit_intercept=True,\n",
       "      l1_ratio=1.0, max_iter=603, normalize=True, positive=False,\n",
       "      precompute=False, random_state=None, selection='cyclic', tol=0.0001,\n",
       "      warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with best parameters from CV\n",
    "model = ElasticNet(l1_ratio=cv_model.l1_ratio_, alpha = cv_model.alpha_, max_iter=cv_model.n_iter_, fit_intercept=True, normalize = True)\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "5d4a9cb7-7b13-0144-91da-32f7eac249cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.586978770942\n"
     ]
    }
   ],
   "source": [
    "# r2 score on training dataset\n",
    "print(r2_score(train_y, model.predict(train_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "27142b96-4827-7d39-74d9-babf075bb6c7"
   },
   "source": [
    "Uncomment below if you want the predictions on the test dataset (LB 0.547+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "5eeac2c9-ee1c-2c79-80af-059a273361c7"
   },
   "outputs": [],
   "source": [
    "# preds = model.predict(test_X)\n",
    "# df_sub = pd.DataFrame({'ID': test_ids, 'y': preds})\n",
    "# df_sub.to_csv('elnet_submission_dummies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "465a432e-5ae8-44e0-6ffe-9df98ead799e"
   },
   "source": [
    "# Feature importance\n",
    "Let's see the importance of each feature based on the absolute value of their coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "add0d507-8417-48df-fb03-33014339a073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 features, reduction of 88.26%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcc78a53a58>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBIAAAF9CAYAAAC5wkvuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc78a53898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = pd.Series(index = train_X.columns, data = np.abs(model.coef_))\n",
    "\n",
    "n_selected_features = (feature_importance>0).sum()\n",
    "print('{0:d} features, reduction of {1:2.2f}%'.format(\n",
    "    n_selected_features,(1-n_selected_features/len(feature_importance))*100))\n",
    "\n",
    "feature_importance.sort_values().tail(30).plot(kind = 'bar', figsize = (18,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "be991a61-5efb-b616-f645-003bb1820758"
   },
   "source": [
    "## It's nice to see how these features compares with those selected by xgboost or other nonlinear methods. Anyway, 88.26% features reduction (with respect to dataset with dummies) looks nice. Besides, the performance on the LB of this linear method seems to be close to those of more sophisticated ones. \n",
    "\n",
    "Vote this notebook if you liked it :P\n",
    "\n",
    "Cheers"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 2,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
