{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yavI9mt4gayF"
   },
   "source": [
    "## Data Augmentation using NLPaug\n",
    "\n",
    "This notebook demostrate the usage of a character augmenter, word augmenter. There are other types such as augmentation for sentences, audio, spectrogram inputs etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:15:03.818048Z",
     "start_time": "2021-04-03T11:15:01.468101Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cF5zJdr-kAPY",
    "outputId": "3e4f51e9-151e-4de0-bf29-17056be5ddf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
      "Collecting nlpaug==0.0.14\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/6c/ca85b6bd29926561229e8c9f677c36c65db9ef1947bfc175e6641bc82ace/nlpaug-0.0.14-py3-none-any.whl (101kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 4.4MB/s \n",
      "\u001b[?25hInstalling collected packages: nlpaug\n",
      "Successfully installed nlpaug-0.0.14\n",
      "Collecting wget==3.2\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9675 sha256=53699b93bdf14ec28540dbe53e9978af5099ce729b974b2c43ec5f5f12e13c59\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Requirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (1.19.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.2.2) (1.15.0)\n",
      "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (2.10)\n"
     ]
    }
   ],
   "source": [
    "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
    "\n",
    "# ===========================\n",
    "\n",
    "!pip install numpy==1.19.5\n",
    "!pip install nlpaug==0.0.14\n",
    "!pip install wget==3.2\n",
    "!pip install matplotlib==3.2.2\n",
    "!pip install requests==2.23.0\n",
    "\n",
    "# ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:15:11.595619Z",
     "start_time": "2021-04-03T11:15:11.593618Z"
    },
    "id": "8yhkOl3cgZ28"
   },
   "outputs": [],
   "source": [
    "# This will be the base text which we will be using throughout this notebook\n",
    "text=\"The quick brown fox jumps over the lazy dog .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:15:15.458928Z",
     "start_time": "2021-04-03T11:15:12.067195Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekFhzIWHUmoj",
    "outputId": "259fdc96-6559-420f-9772-349462187764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nlpaug'...\n",
      "remote: Enumerating objects: 5078, done.\u001b[K\n",
      "remote: Counting objects: 100% (605/605), done.\u001b[K\n",
      "remote: Compressing objects: 100% (387/387), done.\u001b[K\n",
      "remote: Total 5078 (delta 426), reused 358 (delta 215), pack-reused 4473\u001b[K\n",
      "Receiving objects: 100% (5078/5078), 3.17 MiB | 16.74 MiB/s, done.\n",
      "Resolving deltas: 100% (3588/3588), done.\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n",
    "import os\n",
    "!git clone https://github.com/makcedward/nlpaug.git\n",
    "os.environ[\"MODEL_DIR\"] = 'nlpaug/model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Xo3CzNhh-zU"
   },
   "source": [
    "### Augmentation at the Character Level\n",
    "\n",
    "\n",
    "1.   OCR Augmenter: To read textual data from on image, we need an OCR(optical character recognition) model. Once the text is extracted from the image, there may be errors like; '0' instead of an 'o', '2' instead of 'z' and other such similar errors.  \n",
    "2.   Keyboard Augmenter: While typing/texting typos are fairly common this augmenter simulates the errors by substituting characters in words with ones at a similar distance on a keyboard.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:15:15.474943Z",
     "start_time": "2021-04-03T11:15:15.459929Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfAaokTmjzak",
    "outputId": "32ae0735-9724-4c73-b5ae-6c58a3ce86bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Texts:\n",
      "['The quick brown fox jumps 0ver the lazy d0g .', 'The quicr brown fox jump8 ovek the lazy dog .', 'The qoick brown fux jumps over the lazy do9 .']\n"
     ]
    }
   ],
   "source": [
    "# OCR augmenter\n",
    "# import nlpaug.augmenter.char as nac\n",
    "\n",
    "aug = nac.OcrAug()  \n",
    "augmented_texts = aug.augment(text, n=3) # specifying n=3 gives us only 3 augmented versions of the sentence.\n",
    "\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "\n",
    "print(\"Augmented Texts:\")\n",
    "print(augmented_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:15:16.903143Z",
     "start_time": "2021-04-03T11:15:16.880652Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKQCpS35j9Ie",
    "outputId": "ad301a33-bed2-4a00-d34c-083a181c84ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "['The @uick broen fox jumps over the lazy dog .', 'The quick brown fox jumps ovee the ?azy dog .', 'The quick brown fox jumps oveT the lazy dog .']\n"
     ]
    }
   ],
   "source": [
    "# Keyboard Augmenter\n",
    "# import nlpaug.augmenter.word as naw\n",
    "\n",
    "\n",
    "aug = nac.KeyboardAug()\n",
    "augmented_text = aug.augment(text, n=3) # specifying n=3 gives us only 3 augmented versions of the sentence.\n",
    "\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbfPMwZWmper"
   },
   "source": [
    "There are other types of character augmenters too. Their details are avaiable in the links mentioned at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MufLJXsQm4i1"
   },
   "source": [
    "### Augmentation at the Word Level\n",
    "\n",
    "Augmentation is important at the word level as well , here we use word2vec to insert or substitute a similar word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc_K1-niTGFP"
   },
   "source": [
    "**Spelling** **augmentor**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:16:58.980739Z",
     "start_time": "2021-04-03T11:16:58.532879Z"
    },
    "id": "2Qzmv4QCYrJe"
   },
   "outputs": [],
   "source": [
    "# Downloading the required txt file\n",
    "import wget\n",
    "\n",
    "if not os.path.exists(\"spelling_en.txt\"):\n",
    "    wget.download(\"https://raw.githubusercontent.com/makcedward/nlpaug/5238e0be734841b69651d2043df535d78a8cc594/nlpaug/res/word/spelling/spelling_en.txt\")\n",
    "else:\n",
    "    print(\"File already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:17:00.723918Z",
     "start_time": "2021-04-03T11:17:00.619823Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOHrgDIill2F",
    "outputId": "e6b83876-f478-479a-c47e-7a484f8407c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Texts:\n",
      "Te quick brown fox jumps over hthe lazy djg .\n"
     ]
    }
   ],
   "source": [
    "# Substitute word by spelling mistake words dictionary\n",
    "aug = naw.SpellingAug('spelling_en.txt')\n",
    "augmented_texts = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Texts:\")\n",
    "print(augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaeQOtVqTQKG"
   },
   "source": [
    "**Word embeddings augmentor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:42:53.178843Z",
     "start_time": "2021-04-03T11:42:53.163829Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIB9bMi5KWZ5",
    "outputId": "addbe83a-7c57-4eb0-81aa-575700dcb8c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model at GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "gn_vec_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "if not os.path.exists(\"GoogleNews-vectors-negative300.bin\"):\n",
    "    if not os.path.exists(\"../Ch3/GoogleNews-vectors-negative300.bin\"):\n",
    "        # Downloading the reqired model\n",
    "        if not os.path.exists(\"../Ch3/GoogleNews-vectors-negative300.bin.gz\"):\n",
    "            if not os.path.exists(\"GoogleNews-vectors-negative300.bin.gz\"):\n",
    "                wget.download(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\")\n",
    "            gn_vec_zip_path = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "        else:\n",
    "            gn_vec_zip_path = \"../Ch3/GoogleNews-vectors-negative300.bin.gz\"\n",
    "        # Extracting the required model\n",
    "        with gzip.open(gn_vec_zip_path, 'rb') as f_in:\n",
    "            with open(gn_vec_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    else:\n",
    "        gn_vec_path = \"../Ch3/\" + gn_vec_path\n",
    "\n",
    "print(f\"Model at {gn_vec_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jf_QHk-SgegN"
   },
   "source": [
    "Insert word randomly by word embeddings similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:44:12.444755Z",
     "start_time": "2021-04-03T11:43:07.255745Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffUb6s-XTOsQ",
    "outputId": "42d5edef-46fa-4141-ce30-b0306f3bd2af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The Carillion quick brown Emergent fox jumps over the BY lazy dog .\n"
     ]
    }
   ],
   "source": [
    "# model_type: word2vec, glove or fasttext\n",
    "aug = naw.WordEmbsAug(\n",
    "    model_type='word2vec', model_path=gn_vec_path,\n",
    "    action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUB3Nd4Wghd0"
   },
   "source": [
    "Substitute word by word2vec similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:44:12.948639Z",
     "start_time": "2021-04-03T11:44:12.446757Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSeZNfQRfy2l",
    "outputId": "4b00468b-0151-405e-eae1-e6d06e442142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "His quick brown fox jumps morethan the whiny dog .\n"
     ]
    }
   ],
   "source": [
    "aug = naw.WordEmbsAug(\n",
    "    model_type='word2vec', model_path=gn_vec_path,\n",
    "    action=\"substitute\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reALNlOuDI9u"
   },
   "source": [
    "There are many more features which nlpaug offers you can visit the github repo and documentation for further details"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "05_Data_Augmentation_Using_NLPaug.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
