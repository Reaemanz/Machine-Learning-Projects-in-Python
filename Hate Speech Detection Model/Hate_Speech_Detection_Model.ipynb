{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **# Hate Speech Detection Model**\n",
        "\n",
        "Hate Speech Detection is generally a task of sentiment classification. So for training, a model that can classify hate speech from a certain piece of text can be achieved by training it on a data that is generally used to classify sentiments. So for the task of hate speech detection model, I will use the Twitter data."
      ],
      "metadata": {
        "id": "c7oT_rhRuMVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set I will use for the hate speech detection model consists of a test and train set. The training package includes a list of 31,962 tweets, a corresponding ID and a tag 0 or 1 for each tweet. The particular sentiment we need to detect in this dataset is whether or not the tweet is based on hate speech. You can download the dataset from here: \n"
      ],
      "metadata": {
        "id": "zZaMus7Sukjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, let’s get started with the task of building a hate speech detection model. I will simply start with reading the datasets by using the pandas package in python:"
      ],
      "metadata": {
        "id": "OztnlglFu0mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('train.csv')\n",
        "print(\"Training Set:\"% train.columns, train.shape, len(train))\n",
        "test = pd.read_csv('test.csv')\n",
        "print(\"Test Set:\"% test.columns, test.shape, len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4G_7Hyku7xg",
        "outputId": "c4979af4-f6a1-47b1-821f-a08839bd3799"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: (31962, 3) 31962\n",
            "Test Set: (17197, 2) 17197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning**"
      ],
      "metadata": {
        "id": "dNmspQgevKqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def  clean_text(df, text_field):\n",
        "    df[text_field] = df[text_field].str.lower()\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
        "    return df\n",
        "test_clean = clean_text(test, \"tweet\")\n",
        "train_clean = clean_text(train, \"tweet\")"
      ],
      "metadata": {
        "id": "5U8piz_tvUez"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Imbalanced data for Hate Speech Detection Mode**\n",
        "\n",
        "the tweets regarding hate speeches are comparatively lesser than others, so this is a situation of an unbalanced data.\n",
        "\n",
        "If we will fit this data to train our hate speech detection model, then the model will not generalize any hate speech because the data with context to the hate speech is very less than the positive ones. So in this situation, we need to prepare the data to fit properly in our model.\n",
        "\n",
        "There are a number of methods one can use to deal with this. One approach is to use either oversampling or downsampling. In the case of oversampling, we use a function that repeatedly samples, with replacement, from the minority class until the class is the same size as the majority. Let’s see how we can handle this:"
      ],
      "metadata": {
        "id": "0NoUNzebvcCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "train_majority = train_clean[train_clean.label==0]\n",
        "train_minority = train_clean[train_clean.label==1]\n",
        "train_minority_upsampled = resample(train_minority, \n",
        "                                 replace=True,    \n",
        "                                 n_samples=len(train_majority),   \n",
        "                                 random_state=123)\n",
        "train_upsampled = pd.concat([train_minority_upsampled, train_majority])\n",
        "train_upsampled['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW_OUXfGv0Xw",
        "outputId": "fbf43204-329f-4aa8-bfc6-918077dc403c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    29720\n",
              "0    29720\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a Pipeline**\n",
        "\n",
        "For simplicity and reproducibility of the hate speech detection model, I will use the Scikit-Learn’s pipeline with an SGDClassifier, before training our model:"
      ],
      "metadata": {
        "id": "f_Dn3j-Uv899"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "pipeline_sgd = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf',  TfidfTransformer()),\n",
        "    ('nb', SGDClassifier()),])"
      ],
      "metadata": {
        "id": "QC4fiiLYwCpu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the Hate Speech Detection Model**\n",
        "\n",
        "Now, before training the model, let’s split the data into a training set and a test set:"
      ],
      "metadata": {
        "id": "JaGrSxa1wPRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_upsampled['tweet'],\n",
        "                                                    train_upsampled['label'],random_state = 0)"
      ],
      "metadata": {
        "id": "11IJn3CbwVRp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s train the model and predict the results on the test set using the F1 score method:"
      ],
      "metadata": {
        "id": "0--Bs-Bwwcib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline_sgd.fit(X_train, y_train)\n",
        "y_predict = model.predict(X_test)\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnya45DywhpB",
        "outputId": "15830ef6-5655-4406-9406-2c2a30297704"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9698787151805944"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we got an F1 score of 0.96 per cent which is generally appreciatable. This model can now be deployed and used in production."
      ],
      "metadata": {
        "id": "c5WSfxWQwqxP"
      }
    }
  ]
}